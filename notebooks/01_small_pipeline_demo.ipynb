{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "id": "6044645f",
      "cell_type": "markdown",
      "source": "# Small Pipeline Demo (Laptop / CPU)\nThis notebook runs the entire pipeline on a **small sample** of the Amazon Electronics reviews.\nPlace your dataset at `data/Electronics_5.json.gz`. The code writes all artifacts locally.\n\n**Note**: Charts use matplotlib (no seaborn). Each chart is on its own figure.",
      "metadata": {}
    },
    {
      "id": "28821dff",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\n# Optional: if running in a fresh env, install deps (uncomment)\n# !pip install -r ../requirements.txt\n\nimport json, os\nfrom pathlib import Path\nimport pandas as pd\nfrom cfpipe.config import load_config, get_paths, ROOT\ncfg = load_config()\npaths = get_paths(cfg)\nROOT, paths\n",
      "outputs": []
    },
    {
      "id": "b4391299",
      "cell_type": "markdown",
      "source": "## 1) Preprocess (sample 10k)",
      "metadata": {}
    },
    {
      "id": "aa429381",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nfrom cfpipe.preprocess import run as preprocess_run\npreprocess_run(paths.raw_path, paths.cleaned_csv, paths.removed_csv, paths.language_stats, \n               max_rows=100000, sample=cfg[\"defaults\"][\"sample_rows\"], infer_cols=True)\npd.read_csv(paths.cleaned_csv).head()\n",
      "outputs": []
    },
    {
      "id": "a369a07a",
      "cell_type": "markdown",
      "source": "## 2) Chunking (RoBERTa tokenizer)",
      "metadata": {}
    },
    {
      "id": "f578d009",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nfrom cfpipe.chunking import run as chunk_run\nchunk_run(paths.cleaned_csv, paths.chunked_csv, chunk_tokens=cfg[\"defaults\"][\"chunk_tokens\"], overlap=cfg[\"defaults\"][\"chunk_overlap\"])\npd.read_csv(paths.chunked_csv).head()\n",
      "outputs": []
    },
    {
      "id": "5a526efe",
      "cell_type": "markdown",
      "source": "## 3) ABSA (zero-shot aspects + RoBERTa sentiment)",
      "metadata": {}
    },
    {
      "id": "03d7c646",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nfrom cfpipe.absa import run as absa_run\naspects = cfg[\"defaults\"][\"absa_aspects\"]\nabsa_run(paths.chunked_csv, paths.aspect_sentiment, aspects=aspects, batch_size=8, device=\"cpu\")\nimport json\nprint(json.loads(open(paths.aspect_sentiment).read())[0])\n",
      "outputs": []
    },
    {
      "id": "895a2acd",
      "cell_type": "markdown",
      "source": "## 4) Embeddings (distilroberta) + TF-IDF",
      "metadata": {}
    },
    {
      "id": "f66a36a4",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nfrom cfpipe.embed import run as embed_run\nfrom cfpipe.tfidf import run as tfidf_run\nembed_run(paths.chunked_csv, paths.id_to_text_map, paths.dense_memmap, \n          model_name=cfg[\"defaults\"][\"embedding_model_laptop\"], batch_size=64, device=\"cpu\")\ntfidf_run(paths.chunked_csv, paths.tfidf_vectorizer, paths.tfidf_matrix, backend=\"tfidf\", max_features=200000)\n",
      "outputs": []
    },
    {
      "id": "1c081937",
      "cell_type": "markdown",
      "source": "## 5) FAISS (CPU HNSW) + KG",
      "metadata": {}
    },
    {
      "id": "d8d79ee5",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nfrom cfpipe.build_faiss import run as faiss_run\nfrom cfpipe.kg import run as kg_run\n# distilroberta dim=768\nfaiss_run(paths.dense_memmap, dim=768, out_path=paths.faiss_index, index_type=\"hnsw\", gpu=False)\nkg_run(paths.chunked_csv, paths.aspect_sentiment, paths.kg_pickle)\n",
      "outputs": []
    },
    {
      "id": "571f772a",
      "cell_type": "markdown",
      "source": "## 6) Retrieval sanity check",
      "metadata": {}
    },
    {
      "id": "adad164c",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nfrom cfpipe.retriever import HybridRetriever\nr = HybridRetriever(paths.id_to_text_map, cfg[\"defaults\"][\"embedding_model_laptop\"],\n                    paths.faiss_index, paths.tfidf_vectorizer, paths.tfidf_matrix, paths.kg_pickle)\nq = \"battery life of these headphones with noise cancelling\"\nr.search(q, top_k=5)\n",
      "outputs": []
    },
    {
      "id": "bc9c06bd",
      "cell_type": "markdown",
      "source": "## 7) Visualizations (matplotlib)\nWe will plot: ratings histogram, sentiment pie, top negative aspects bar, and sentiment over time.",
      "metadata": {}
    },
    {
      "id": "5999cac5",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport json\n\ndf_chunks = pd.read_csv(paths.chunked_csv)\naspect = json.load(open(paths.aspect_sentiment))\ndf_absa = pd.DataFrame(aspect)\n\n# Ratings histogram\nfig, ax = plt.subplots()\ndf_clean = pd.read_csv(paths.cleaned_csv)\nax.hist(df_clean['rating'].dropna(), bins=10)\nax.set_title(\"Ratings distribution\")\nax.set_xlabel(\"Stars\"); ax.set_ylabel(\"Count\")\nplt.show()\n",
      "outputs": []
    },
    {
      "id": "1090ded1",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\n# Sentiment pie\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndf_absa = pd.DataFrame(json.load(open(paths.aspect_sentiment)))\nfig, ax = plt.subplots()\nsent_counts = df_absa['sentiment'].value_counts()\nax.pie(sent_counts.values, labels=sent_counts.index, autopct=\"%1.1f%%\")\nplt.show()\n",
      "outputs": []
    },
    {
      "id": "c18081de",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\n# Top negative aspects bar\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndf_absa = pd.DataFrame(json.load(open(paths.aspect_sentiment)))\nneg = df_absa[df_absa['sentiment']=='negative']\nfreq = {}\nfor xs in neg['aspects']:\n    for a in xs: freq[a] = freq.get(a, 0) + 1\ntop = sorted(freq.items(), key=lambda x: -x[1])[:15]\nfig, ax = plt.subplots()\nax.bar([a for a,_ in top], [c for _,c in top])\nplt.xticks(rotation=45, ha=\"right\")\nax.set_ylabel(\"Count\"); ax.set_title(\"Top negative aspects\")\nplt.show()\n",
      "outputs": []
    },
    {
      "id": "799804ca",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\n# Sentiment over time (avg signed score)\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndf_chunks = pd.read_csv(paths.chunked_csv, usecols=[\"chunk_id\",\"unix_time\"])\ndf_absa = pd.DataFrame(json.load(open(paths.aspect_sentiment)))\ndf = df_absa.merge(df_chunks, on=\"chunk_id\", how=\"left\")\ndf['ts'] = pd.to_datetime(df['unix_time'], unit='s', errors='coerce')\ndf['month'] = df['ts'].dt.to_period('M').astype(str)\ndf['signed'] = df['sentiment'].apply(lambda s: 1.0 if s=='positive' else -1.0) * df['sentiment_score'].astype(float)\ntrend = df.groupby('month')['signed'].mean().reset_index()\nfig, ax = plt.subplots()\nax.plot(trend['month'], trend['signed'])\nplt.xticks(rotation=45, ha=\"right\"); ax.set_ylabel(\"Avg sentiment score\"); ax.set_title(\"Trend over time\")\nplt.show()\n",
      "outputs": []
    },
    {
      "id": "075be2bc",
      "cell_type": "markdown",
      "source": "## 8) Start API + Dashboard (run in terminal)\n```bash\nuvicorn cfpipe.api_server:app --port 8000\n\nstreamlit run src/cfpipe/dashboard.py\n```",
      "metadata": {}
    }
  ]
}